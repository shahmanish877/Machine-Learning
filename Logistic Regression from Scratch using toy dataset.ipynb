{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Author**: Rajan Adhikari\n",
    "\n",
    "**Program**: Logistic Regression on Toy Dataset\n",
    "\n",
    "**Objective**: To illustrate the scratch implementation of Logistic Regression\n",
    "\n",
    "**Prepared for**: MDS | School of Mathematical Science\n",
    "\n",
    "**Date**: 8/21/2023\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a33a6b1ca980eb4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:27:01.217813900Z",
     "start_time": "2023-08-21T16:27:01.198836500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 11\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "        This is the scratch implementation of Logistic Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.param = {}\n",
    "        self.m, self.n = X.shape\n",
    "        self.param['W'] = np.random.randn(self.n,1) * 0.001\n",
    "        self.param['b'] = np.zeros(1)\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.result = pd.DataFrame()\n",
    "\n",
    "    def train(self, alpha = 0.001, epochs = 10):\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch: \", epoch, end=\"\")\n",
    "            z = np.dot(self.X,self.param['W']) + self.param['b']\n",
    "\n",
    "            self.y_pred = self.sigmoid(z)\n",
    "            self.result[0] = self.y\n",
    "\n",
    "            #Update the parameters\n",
    "            self.param['W'] = self.param['W'] - alpha * 1/self.m * np.dot(self.X.transpose(), (self.y_pred - np.reshape(self.y, (self.m, 1))))\n",
    "            self.param['b'] =  self.param['b'] - alpha * 1/self.m * np.sum(self.y_pred - np.reshape(self.y, (self.m, 1)))\n",
    "\n",
    "            self.y_pred = self.sigmoid(np.dot(self.X,self.param['W']) + self.param['b'])\n",
    "            loss = self.loss(self.y, self.y_pred)\n",
    "\n",
    "            self.result[1] = self.y_pred\n",
    "            print(\", loss = \", loss)\n",
    "\n",
    "        print(\"\\nFinal Loss is \", loss)\n",
    "        print(\"Coefficients are: \\n W: {}, b = {}\".format(self.param['W'], self.param['b']))\n",
    "\n",
    "    @staticmethod\n",
    "    def loss(y, y_pred):\n",
    "        y_zero_loss =  y.T.dot(np.log(y_pred))\n",
    "        y_one_loss = (1-y).T.dot(np.log(1 - y_pred))\n",
    "\n",
    "        return -np.sum(y_zero_loss + y_one_loss)/len(y)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1.0/(1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(np.dot(X,self.param['W']) + self.param['b'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:27:01.648402300Z",
     "start_time": "2023-08-21T16:27:01.631402700Z"
    }
   },
   "id": "9110dc3d97c291bf"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data(no_of_data = 100, no_of_features = 4):\n",
    "    features, target = make_classification(n_samples=no_of_data,\n",
    "                                              n_features=no_of_features,\n",
    "                                              n_classes=2,\n",
    "                                              random_state=SEED)\n",
    "\n",
    "    return features, target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:27:02.093122200Z",
     "start_time": "2023-08-21T16:27:02.069616600Z"
    }
   },
   "id": "e415d1a0eb8830a0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, loss =  0.6369515532007411\n",
      "Epoch:  1, loss =  0.5938916895497949\n",
      "Epoch:  2, loss =  0.5607616106735371\n",
      "Epoch:  3, loss =  0.5343849052409058\n",
      "Epoch:  4, loss =  0.5127474809149306\n",
      "Epoch:  5, loss =  0.49455704392542293\n",
      "Epoch:  6, loss =  0.4789600311882209\n",
      "Epoch:  7, loss =  0.4653735203317431\n",
      "Epoch:  8, loss =  0.45338620460843626\n",
      "Epoch:  9, loss =  0.4426990131263279\n",
      "Epoch:  10, loss =  0.43308854288069726\n",
      "Epoch:  11, loss =  0.424383879358419\n",
      "Epoch:  12, loss =  0.4164514811530867\n",
      "Epoch:  13, loss =  0.40918505582204906\n",
      "Epoch:  14, loss =  0.40249860853714237\n",
      "Epoch:  15, loss =  0.3963215591280728\n",
      "Epoch:  16, loss =  0.39059523964723425\n",
      "Epoch:  17, loss =  0.3852703336467681\n",
      "Epoch:  18, loss =  0.3803049709000468\n",
      "Epoch:  19, loss =  0.375663286878504\n",
      "Epoch:  20, loss =  0.3713143174777097\n",
      "Epoch:  21, loss =  0.36723113944315794\n",
      "Epoch:  22, loss =  0.36339019353206153\n",
      "Epoch:  23, loss =  0.3597707454472173\n",
      "Epoch:  24, loss =  0.35635445196505405\n",
      "Epoch:  25, loss =  0.35312500833324995\n",
      "Epoch:  26, loss =  0.350067859145087\n",
      "Epoch:  27, loss =  0.3471699593008164\n",
      "Epoch:  28, loss =  0.34441957486775543\n",
      "Epoch:  29, loss =  0.3418061160059851\n",
      "Epoch:  30, loss =  0.33931999587829326\n",
      "Epoch:  31, loss =  0.33695251077960436\n",
      "Epoch:  32, loss =  0.3346957377204029\n",
      "Epoch:  33, loss =  0.33254244646414255\n",
      "Epoch:  34, loss =  0.33048602361018187\n",
      "Epoch:  35, loss =  0.32852040677473604\n",
      "Epoch:  36, loss =  0.32664002728433705\n",
      "Epoch:  37, loss =  0.32483976008272386\n",
      "Epoch:  38, loss =  0.3231148797803177\n",
      "Epoch:  39, loss =  0.32146102195851917\n",
      "Epoch:  40, loss =  0.3198741489888679\n",
      "Epoch:  41, loss =  0.3183505197471492\n",
      "Epoch:  42, loss =  0.31688666270058663\n",
      "Epoch:  43, loss =  0.315479351926802\n",
      "Epoch:  44, loss =  0.3141255856897084\n",
      "Epoch:  45, loss =  0.31282256725267443\n",
      "Epoch:  46, loss =  0.31156768765527754\n",
      "Epoch:  47, loss =  0.31035851021847155\n",
      "Epoch:  48, loss =  0.30919275657536754\n",
      "Epoch:  49, loss =  0.3080682940521687\n",
      "Epoch:  50, loss =  0.30698312424696234\n",
      "Epoch:  51, loss =  0.30593537267378923\n",
      "Epoch:  52, loss =  0.3049232793562331\n",
      "Epoch:  53, loss =  0.3039451902691886\n",
      "Epoch:  54, loss =  0.3029995495398532\n",
      "Epoch:  55, loss =  0.3020848923296628\n",
      "Epoch:  56, loss =  0.3011998383281245\n",
      "Epoch:  57, loss =  0.30034308579749874\n",
      "Epoch:  58, loss =  0.2995134061142426\n",
      "Epoch:  59, loss =  0.29870963875918655\n",
      "Epoch:  60, loss =  0.29793068671371564\n",
      "Epoch:  61, loss =  0.29717551222386346\n",
      "Epoch:  62, loss =  0.29644313289830154\n",
      "Epoch:  63, loss =  0.2957326181097863\n",
      "Epoch:  64, loss =  0.2950430856727876\n",
      "Epoch:  65, loss =  0.29437369877280706\n",
      "Epoch:  66, loss =  0.29372366312537096\n",
      "Epoch:  67, loss =  0.2930922243448637\n",
      "Epoch:  68, loss =  0.29247866550531937\n",
      "Epoch:  69, loss =  0.2918823048770174\n",
      "Epoch:  70, loss =  0.2913024938242708\n",
      "Epoch:  71, loss =  0.29073861485117475\n",
      "Epoch:  72, loss =  0.2901900797833148\n",
      "Epoch:  73, loss =  0.28965632807453656\n",
      "Epoch:  74, loss =  0.28913682522887174\n",
      "Epoch:  75, loss =  0.28863106132860084\n",
      "Epoch:  76, loss =  0.2881385496602358\n",
      "Epoch:  77, loss =  0.28765882543092447\n",
      "Epoch:  78, loss =  0.2871914445684303\n",
      "Epoch:  79, loss =  0.28673598259842625\n",
      "Epoch:  80, loss =  0.2862920335933731\n",
      "Epoch:  81, loss =  0.28585920918773255\n",
      "Epoch:  82, loss =  0.2854371376547021\n",
      "Epoch:  83, loss =  0.28502546304005105\n",
      "Epoch:  84, loss =  0.28462384434899934\n",
      "Epoch:  85, loss =  0.28423195478240393\n",
      "Epoch:  86, loss =  0.2838494810188173\n",
      "Epoch:  87, loss =  0.283476122539251\n",
      "Epoch:  88, loss =  0.2831115909917257\n",
      "Epoch:  89, loss =  0.2827556095929148\n",
      "Epoch:  90, loss =  0.2824079125643913\n",
      "Epoch:  91, loss =  0.28206824460118246\n",
      "Epoch:  92, loss =  0.2817363603705019\n",
      "Epoch:  93, loss =  0.2814120240386934\n",
      "Epoch:  94, loss =  0.2810950088245603\n",
      "Epoch:  95, loss =  0.2807850965773921\n",
      "Epoch:  96, loss =  0.28048207737811853\n",
      "Epoch:  97, loss =  0.28018574916213584\n",
      "Epoch:  98, loss =  0.2798959173624526\n",
      "Epoch:  99, loss =  0.27961239457189857\n",
      "\n",
      "Final Loss is  0.27961239457189857\n",
      "Coefficients are: \n",
      " W: [[-0.63622246]\n",
      " [ 0.6138087 ]\n",
      " [ 0.47391261]\n",
      " [ 1.14212836]], b = [0.07062205]\n"
     ]
    }
   ],
   "source": [
    "no_of_data = 100000\n",
    "no_of_features = 4\n",
    "X, y = generate_data(no_of_data, no_of_features)\n",
    "alpha = 0.1\n",
    "epochs = 100\n",
    "log_model = LogisticRegression(X, y)\n",
    "log_model.train(alpha, epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:27:03.087459700Z",
     "start_time": "2023-08-21T16:27:02.516551900Z"
    }
   },
   "id": "f7df4c9504732097"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e6bf93bb1378e51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
